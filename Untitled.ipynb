{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d76856f5-481a-4dfe-a7e4-c7be07ff3afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow import keras\n",
    "\n",
    "threshold = 0.75  # THRESHOLD\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "model = keras.models.load_model('TSR.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bf478bb-4a03-4966-bbb8-d2b488bd1884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(imgBGR, erode_dilate=True):  # pre-processing fro detect signs in  image.\n",
    "    rows, cols, _ = imgBGR.shape\n",
    "    imgHSV = cv2.cvtColor(imgBGR, cv2.COLOR_BGR2HSV)\n",
    "    Bmin = np.array([100, 43, 46])\n",
    "    Bmax = np.array([124, 255, 255])\n",
    "    img_Bbin = cv2.inRange(imgHSV, Bmin, Bmax)\n",
    "\n",
    "    Rmin1 = np.array([0, 43, 46])\n",
    "    Rmax1 = np.array([10, 255, 255])\n",
    "    img_Rbin1 = cv2.inRange(imgHSV, Rmin1, Rmax1)\n",
    "\n",
    "    Rmin2 = np.array([156, 43, 46])\n",
    "    Rmax2 = np.array([180, 255, 255])\n",
    "    img_Rbin2 = cv2.inRange(imgHSV, Rmin2, Rmax2)\n",
    "    img_Rbin = np.maximum(img_Rbin1, img_Rbin2)\n",
    "    img_bin = np.maximum(img_Bbin, img_Rbin)\n",
    "\n",
    "    if erode_dilate is True:\n",
    "        kernelErosion = np.ones((3, 3), np.uint8)\n",
    "        kernelDilation = np.ones((3, 3), np.uint8)\n",
    "        img_bin = cv2.erode(img_bin, kernelErosion, iterations=2)\n",
    "        img_bin = cv2.dilate(img_bin, kernelDilation, iterations=2)\n",
    "\n",
    "    return img_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "354a5f57-2379-436a-b912-ac24d5120ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contour_detect(img_bin, min_area, max_area=-1, wh_ratio=2.0):\n",
    "    rects = []\n",
    "    contours, _ = cv2.findContours(img_bin.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    if len(contours) == 0:\n",
    "        return rects\n",
    "\n",
    "    max_area = img_bin.shape[0] * img_bin.shape[1] if max_area < 0 else max_area\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area >= min_area and area <= max_area:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            if 1.0 * w / h < wh_ratio and 1.0 * h / w < wh_ratio:\n",
    "                rects.append([x, y, w, h])\n",
    "    return rects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59b0d090-c22b-49bd-b78d-5711b17b452e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return img\n",
    "\n",
    "\n",
    "def equalize(img):\n",
    "    img = cv2.equalizeHist(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def preprocessing(img):\n",
    "    img = grayscale(img)\n",
    "    img = equalize(img)\n",
    "    img = img / 255\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69fdf495-ebb2-4321-8d9c-ae29ed09b40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCalssName(classNo):\n",
    "    if classNo == 0:\n",
    "        return 'Speed Limit 20 km/h'\n",
    "    elif classNo == 1:\n",
    "        return 'Speed Limit 30 km/h'\n",
    "    elif classNo == 2:\n",
    "        return 'Speed Limit 50 km/h'\n",
    "    elif classNo == 3:\n",
    "        return 'Speed Limit 60 km/h'\n",
    "    elif classNo == 4:\n",
    "        return 'Speed Limit 70 km/h'\n",
    "    elif classNo == 5:\n",
    "        return 'Speed Limit 80 km/h'\n",
    "    elif classNo == 6:\n",
    "        return 'End of Speed Limit 80 km/h'\n",
    "    elif classNo == 7:\n",
    "        return 'Speed Limit 100 km/h'\n",
    "    elif classNo == 8:\n",
    "        return 'Speed Limit 120 km/h'\n",
    "    elif classNo == 9:\n",
    "        return 'No passing'\n",
    "    elif classNo == 10:\n",
    "        return 'No passing for vechiles over 3.5 metric tons'\n",
    "    elif classNo == 11:\n",
    "        return 'Right-of-way at the next intersection'\n",
    "    elif classNo == 12:\n",
    "        return 'Priority road'\n",
    "    elif classNo == 13:\n",
    "        return 'Yield'\n",
    "    elif classNo == 14:\n",
    "        return 'Stop'\n",
    "    elif classNo == 15:\n",
    "        return 'No vechiles'\n",
    "    elif classNo == 16:\n",
    "        return 'Vechiles over 3.5 metric tons prohibited'\n",
    "    elif classNo == 17:\n",
    "        return 'No entry'\n",
    "    elif classNo == 18:\n",
    "        return 'General caution'\n",
    "    elif classNo == 19:\n",
    "        return 'Dangerous curve to the left'\n",
    "    elif classNo == 20:\n",
    "        return 'Dangerous curve to the right'\n",
    "    elif classNo == 21:\n",
    "        return 'Double curve'\n",
    "    elif classNo == 22:\n",
    "        return 'Bumpy road'\n",
    "    elif classNo == 23:\n",
    "        return 'Slippery road'\n",
    "    elif classNo == 24:\n",
    "        return 'Road narrows on the right'\n",
    "    elif classNo == 25:\n",
    "        return 'Road work'\n",
    "    elif classNo == 26:\n",
    "        return 'Traffic signals'\n",
    "    elif classNo == 27:\n",
    "        return 'Pedestrians'\n",
    "    elif classNo == 28:\n",
    "        return 'Children crossing'\n",
    "    elif classNo == 29:\n",
    "        return 'Bicycles crossing'\n",
    "    elif classNo == 30:\n",
    "        return 'Beware of ice/snow'\n",
    "    elif classNo == 31:\n",
    "        return 'Wild animals crossing'\n",
    "    elif classNo == 32:\n",
    "        return 'End of all speed and passing limits'\n",
    "    elif classNo == 33:\n",
    "        return 'Turn right ahead'\n",
    "    elif classNo == 34:\n",
    "        return 'Turn left ahead'\n",
    "    elif classNo == 35:\n",
    "        return 'Ahead only'\n",
    "    elif classNo == 36:\n",
    "        return 'Go straight or right'\n",
    "    elif classNo == 37:\n",
    "        return 'Go straight or left'\n",
    "    elif classNo == 38:\n",
    "        return 'Keep right'\n",
    "    elif classNo == 39:\n",
    "        return 'Keep left'\n",
    "    elif classNo == 40:\n",
    "        return 'Roundabout mandatory'\n",
    "    elif classNo == 41:\n",
    "        return 'End of no passing'\n",
    "    elif classNo == 42:\n",
    "        return 'End of no passing by vechiles over 3.5 metric tons'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c26320f-52d7-48ba-8309-5cd48dc6d61d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'contour_detect' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbin image\u001b[39m\u001b[38;5;124m\"\u001b[39m, img_bin)\n\u001b[0;32m     19\u001b[0m min_area \u001b[38;5;241m=\u001b[39m img_bin\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m25\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m25\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m rects \u001b[38;5;241m=\u001b[39m \u001b[43mcontour_detect\u001b[49m(img_bin, min_area\u001b[38;5;241m=\u001b[39mmin_area)   \u001b[38;5;66;03m# get x,y,h and w.\u001b[39;00m\n\u001b[0;32m     21\u001b[0m img_bbx \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rect \u001b[38;5;129;01min\u001b[39;00m rects:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'contour_detect' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "def preprocess_img(image, show=False):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)  # Apply thresholding as an example\n",
    "    if show:\n",
    "        cv2.imshow(\"Processed Image\", binary)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    return binary\n",
    "if __name__ == \"__main__\":\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cols = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    rows = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    while (1):\n",
    "        ret, img = cap.read()\n",
    "        img_bin = preprocess_img(img, False)\n",
    "        cv2.imshow(\"bin image\", img_bin)\n",
    "        min_area = img_bin.shape[0] * img.shape[1] / (25 * 25)\n",
    "        rects = contour_detect(img_bin, min_area=min_area)   # get x,y,h and w.\n",
    "        img_bbx = img.copy()\n",
    "        for rect in rects:\n",
    "            xc = int(rect[0] + rect[2] / 2)\n",
    "            yc = int(rect[1] + rect[3] / 2)\n",
    "\n",
    "            size = max(rect[2], rect[3])\n",
    "            x1 = max(0, int(xc - size / 2))\n",
    "            y1 = max(0, int(yc - size / 2))\n",
    "            x2 = min(cols, int(xc + size / 2))\n",
    "            y2 = min(rows, int(yc + size / 2))\n",
    "\n",
    "            # rect[2] is width and rect[3] for height\n",
    "            if rect[2] > 100 and rect[3] > 100:             #only detect those signs whose height and width >100\n",
    "                cv2.rectangle(img_bbx, (rect[0], rect[1]), (rect[0] + rect[2], rect[1] + rect[3]), (0, 0, 255), 2)\n",
    "            crop_img = np.asarray(img[y1:y2, x1:x2])\n",
    "            crop_img = cv2.resize(crop_img, (30, 30))  # Resize the image to match the model's input size\n",
    "            crop_img = cv2.cvtColor(crop_img, cv2.COLOR_GRAY2BGR)  # Convert the image to 3-channel (RGB)\n",
    "            \n",
    "            # For Neural Network input, you can normalize the pixel values\n",
    "            crop_img = crop_img / 255.0  # Scale the pixel values between 0 and 1\n",
    "            \n",
    "            crop_img = crop_img.reshape(1, 30, 30, 3)  # Reshape the image to match the model's input shape\n",
    "            \n",
    "            predictions = model.predict(crop_img)  # Make predictions\n",
    "            classIndex = np.argmax(predictions)  # Derive the class index with the highest probability\n",
    "            probabilityValue = np.amax(predictions)  # Get the maximum probability \n",
    "\n",
    "            probabilityValue = np.amax(predictions)  # Get the maximum probability\n",
    "\n",
    "            if probabilityValue > threshold:\n",
    "                # Write class name on the output screen\n",
    "                cv2.putText(img_bbx, str(classIndex) + \" \" + str(getCalssName(classIndex)), (rect[0], rect[1] - 10),\n",
    "                           font, 0.75, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    # Write probability value on the output screen\n",
    "                cv2.putText(img_bbx, str(round(probabilityValue * 100, 2)) + \"%\", (rect[0], rect[1] - 40), font, 0.75,\n",
    "                (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow(\"detect result\", img_bbx)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):           # q for quit\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f77c671-0844-485b-9374-3d0e80a86a40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
